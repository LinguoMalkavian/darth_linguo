{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which experiment would you like to consolidate results for? exp-2.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "res_top = os.path.abspath(\"../results/\")\n",
    "\n",
    "consol_folder = os.path.join(res_top,\"consolidated\")\n",
    "if not os.path.isdir(consol_folder):\n",
    "    os.mkdir(consol_folder)\n",
    "    \n",
    "\n",
    "metrics = [\"best_validation_accuracy\",\n",
    "  \"best_validation_G_accuracy\",\n",
    "  \"best_validation_AA_accuracy\",\n",
    "  \"best_validation_RV_accuracy\",\n",
    "  \"best_validation_VA_accuracy\",\n",
    "   \"training_accuracy\",\n",
    "  \"training_G_accuracy\",\n",
    "  \"training_AA_accuracy\",\n",
    "  \"training_RV_accuracy\",\n",
    "  \"training_VA_accuracy\",\n",
    "    \"best_epoch\",]\n",
    "\n",
    "experiment = input(\"Which experiment would you like to consolidate results for?\")\n",
    "\n",
    "consolidated = {}\n",
    "\n",
    "column_set = set()\n",
    "\n",
    "for fullname in os.listdir(res_top):\n",
    "    parts = fullname.split('_')\n",
    "    exp_type = parts[0]\n",
    "    if exp_type == experiment:\n",
    "        row_condition = parts[1]\n",
    "        file_path = os.path.join(res_top, fullname, 'metrics.json')\n",
    "        consolidated[row_condition] = {}\n",
    "        try :\n",
    "            with open(file_path,\"r\") as exp_file:\n",
    "                results = json.loads(exp_file.read())\n",
    "            for metric in metrics:\n",
    "                consolidated[row_condition][metric] = results[metric]\n",
    "        except FileNotFoundError:\n",
    "            print(\"Metrics for {} where not available\".format(row_condition))\n",
    "fieldnames = list(column_set)\n",
    "fieldnames.sort()\n",
    "fieldnames.insert(0,\"archi\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from 35 conditions of experiment exp-2.1 where consolidated in /home/lab/Pablo/darth_linguo/results/consolidated/exp-2.1.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "consol_fn = os.path.join(consol_folder, experiment + \".csv\")\n",
    "fieldnames = ['Condition'] + metrics[:]\n",
    "with open(consol_fn,\"w\") as consol_file:\n",
    "    writer = csv.DictWriter(consol_file, fieldnames)\n",
    "    writer.writeheader()\n",
    "    for rowname in consolidated:\n",
    "        row = consolidated[rowname]\n",
    "        row['Condition'] = rowname\n",
    "        writer.writerow(row)\n",
    "    message = \"Results from {} conditions of experiment {} where consolidated in {}\"\n",
    "    message = message.format(len(consolidated), experiment, consol_fn)\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_validation_accuracy': defaultdict(dict, {}),\n",
       " 'best_epoch': defaultdict(dict, {}),\n",
       " 'training_accuracy': defaultdict(dict, {})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list of all experiments\n",
    "import os\n",
    "\n",
    "res_top = os.path.abspath(\"../results/\")\n",
    "exp_list = []\n",
    "for fullname in os.listdir(res_top):\n",
    "    if fullname.startswith(\"exp-\"):\n",
    "        exp_list.append(fullname)\n",
    "        \n",
    "bash_arr = \"(\" + \" \".join(exp_list) + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(exp-1.2_pretrained-cont exp-1_quarter-WS_350-1000_lab exp-1.3_64-512 exp-1.3_512-512 exp-1_all-WS_350-1000_lab exp-2.1_3uni-3-layer exp-1.1_256-256 exp-1.1_512-1024 exp-2.1_6bi-3-layer exp-1.3_256-512 exp-2.1_4bi-1-layer exp-2.1_2uni-2-layer exp-1.1_512-512 exp-1.1_128-128 exp-1.1_32-32 exp-2.1_1uni-1-layer exp-1_half-WS_350-1000_lab exp-2.1_5bi-2-layer exp-1.2_pretrained-freeze exp-1.1_64-64 exp-1.3_128-512 exp-1.2_random exp-1_no-WS_350-1000_lab exp-1.3_32-512 exp-1.3_16-512)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bash_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allen]",
   "language": "python",
   "name": "conda-env-allen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
