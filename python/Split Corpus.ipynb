{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1297109, 1575061]\n",
      "1297109\n",
      "277952\n",
      "277952\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "corpusName = \"euro_mini\"\n",
    "basePath = \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
    "dataPath = basePath + \"/Data/\" + corpusName +\"/\" + corpusName\n",
    "\n",
    "\n",
    "# Load the full corpus\n",
    "corpus_name = \"europarl-V7\"\n",
    "infile_name = \"Corpora/europarl-v7.es\"\n",
    "\n",
    "infile = open(infile_name,\"r\")\n",
    "\n",
    "raw_sentences = []\n",
    "\n",
    "for line in infile.readlines():\n",
    "    line = line.rstrip()\n",
    "    if line and line[-1] == \".\":\n",
    "        raw_sentences.append(line)\n",
    "\n",
    "infile.close()\n",
    "\n",
    "random.shuffle(raw_sentences)\n",
    "#Points at which to cut off the data, first is train, then test, remaining is verification\n",
    "proportions = [0.70,0.85]\n",
    "cutoffs = [int(math.floor(len(raw_sentences))*prop) for prop in proportions] \n",
    "print(cutoffs)\n",
    "sentences_train = raw_sentences[:cutoffs[0]]\n",
    "sentences_test = raw_sentences[cutoffs[0]:cutoffs[1]]\n",
    "sentences_verif = raw_sentences[cutoffs[1]:]\n",
    "print(len(sentences_train))\n",
    "print(len(sentences_test))\n",
    "print(len(sentences_verif))\n",
    "\n",
    "def split_n_output(sentences,kind,corpus):\n",
    "    cutoff = math.floor(len(sentences)/2.0)\n",
    "    sentences2keep = sentences[:cutoff]\n",
    "    sentences2corrupt = sentences[cutoff:]\n",
    "    file2keep_fn = \"Data/{corpus}.{kind}.2keep\".format(corpus=corpus,kind=kind)\n",
    "    file2corrupt_fn = \"Data/{corpus}.{kind}.2corrupt\".format(corpus=corpus,kind=kind)\n",
    "    \n",
    "    file2keep = open(file2keep_fn,\"w\")\n",
    "    file2corrupt = open(file2corrupt_fn,\"w\")\n",
    "    for line in sentences2keep:\n",
    "        file2keep.write(line+\"\\n\")\n",
    "    for line in sentences2corrupt:\n",
    "        file2corrupt.write(line+\"\\n\")\n",
    "    file2keep.close()\n",
    "    file2corrupt.close()\n",
    "    \n",
    "split_n_output(sentences_train,\"train\", corpus_name)\n",
    "split_n_output(sentences_test,\"test\", corpus_name)\n",
    "split_n_output(sentences_verif,\"verif\", corpus_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = open(\"example\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [\"yo\",\"tu\",\"el\",\"nosotros\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example.writelines(lines)\n",
    "example.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
