{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language models\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import corpus_tools\n",
    "import corruption_tools\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Loading language models\")\n",
    "nlp_med = spacy.load('es_core_news_md')\n",
    "\n",
    "# Initialize the array of corruptors\n",
    "corruptortypes = [\"RV\", \"VA\", \"AA\"]\n",
    "corruptors = {}\n",
    "corruptors[\"RV\"] = corruption_tools.VerbRemover(\"verbRM\", nlp_med)\n",
    "corruptors[\"VA\"] = corruption_tools.VerbInflCorruptor(\"verbInfl\", nlp_med)\n",
    "corruptors[\"AA\"] = corruption_tools.AdjInflCorruptor(\"adjInfl\", nlp_med)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 86.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining Corruption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302762it [1:01:47, 81.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RV:145432\n",
      "VA:103787\n",
      "AA:160744\n",
      "Total: 409963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize counters for corrupted sentences\n",
    "corruptCount = {}\n",
    "uncorrupted_count = 0\n",
    "for typ in corruptortypes:\n",
    "    corruptCount[typ] = 0\n",
    "\n",
    "# Load sentence generator\n",
    "#in_corpus_filename = sys.argv[1]\n",
    "corpus_basename = os.path.abspath(\"../Data/exp3-pairtest/exp3-pairtest\")\n",
    "\n",
    "in_corpus_fn = corpus_basename + \"-base\"\n",
    "in_corpus_file = open(in_corpus_fn, \"r\")\n",
    "\n",
    "\n",
    "sentence_gen = corpus_tools.sentence_generator(in_corpus_file, nlp_med)\n",
    "corruptCount={}\n",
    "# Create outfiles for each type of corrupted sentence\n",
    "corrupted_files = {}\n",
    "uncorrupted_files = {}\n",
    "for kind in corruptortypes:\n",
    "    corrupted_name = corpus_basename + \"_\" + kind + \"_corrupted\"\n",
    "    corrupted_files[kind] = open(corrupted_name, \"w\")\n",
    "    uncorrupted_name = corpus_basename + \"_\" + kind + \"_uncorrupted\"\n",
    "    uncorrupted_files[kind] = open(uncorrupted_name, \"w\")\n",
    "    corruptCount[kind]=0\n",
    "    \n",
    "processed_count = 0\n",
    "# Iterate parsed sentences and test for coruptibility\n",
    "print(\"Begining Corruption\")\n",
    "for parsed_sentence in tqdm(sentence_gen):\n",
    "\n",
    "    # Test for each corruptor, store the possible transformations\n",
    "    possib_trans = {}\n",
    "    for cor_type in corruptortypes:\n",
    "        target = corruptors[cor_type].test_possible(parsed_sentence)\n",
    "        if target is not None:\n",
    "            possib_trans[cor_type] = target\n",
    "    #Execute each of the possible transformations\n",
    "    for kind in possib_trans:\n",
    "        # Corrupt sentence\n",
    "        target = possib_trans[kind]\n",
    "        corruptedVersion = corruptors[kind].transform(parsed_sentence, target)\n",
    "        if corruptedVersion is not None:\n",
    "            # Save corrupted sentence to corresponding file\n",
    "            outline = \"0 {} {} <eos>\\n\".format(kind,corruptedVersion)\n",
    "            corrupted_files[kind].write(outline)\n",
    "            \n",
    "            uncorrupted = parsed_sentence.text\n",
    "            unc_line = \"1 G {} <eos>\\n\".format(uncorrupted)\n",
    "            uncorrupted_files[kind].write(unc_line)\n",
    "            corruptCount[kind] +=1\n",
    "# Close files\n",
    "for kind in corruptortypes:\n",
    "    corrupted_files[kind].close()\n",
    "    uncorrupted_files[kind].close()\n",
    "# Print summary to console\n",
    "total = 0\n",
    "for trans_type in corruptCount:\n",
    "    print(trans_type + \":\" + str(corruptCount[trans_type]))\n",
    "    total += corruptCount[trans_type]\n",
    "print(\"Total: {0}\".format(total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=nlp_med(\"Yo soy una oracion , sin tildes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yo soy una oracion , sin tildes'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp)",
   "language": "python",
   "name": "allenlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
